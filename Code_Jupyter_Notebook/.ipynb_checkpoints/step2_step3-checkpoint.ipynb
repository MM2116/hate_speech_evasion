{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string \n",
    "\n",
    "#LOAD Exp2 Dataset with hate words\n",
    "with open('hate_json_exp2','r') as json_file:\n",
    "    json_file_data = json.load(json_file)\n",
    "\n",
    "json_hate_word_list = []\n",
    "for element in json_file_data:\n",
    "    json_hate_word_list.append(element['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load more hate words + negative words\n",
    "with open('sample_sentences.txt','r') as sentences_file:\n",
    "    sent_string = sentences_file.read()\n",
    "    \n",
    "with open('augment_hate_words.txt','r') as augment_words:\n",
    "    json_hate_word_list = json_hate_word_list + augment_words.read().split(', ')\n",
    "\n",
    "with open('negative_words.txt','r') as negative_words:\n",
    "    json_hate_word_list = json_hate_word_list + negative_words.read().split('\\n')\n",
    "\n",
    "json_hate_word_list = list(set(json_hate_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['idiot'], ['stupid'], ['idiots', 'uneducated'], ['idiots', 'backward', 'susceptible', 'lies'], ['stupid', 'ignorant'], ['stupid', 'wrong'], ['idiots'], ['moron'], [], ['jews', 'deadly', 'virus', 'kill', 'jews'], ['abomination'], ['blacks'], [], ['blame', 'crime', 'crime', 'blame', 'deny', 'damage', 'pervert'], []]\n"
     ]
    }
   ],
   "source": [
    "#Finding intersection between sample sentence and exp data\n",
    "sample_sentence_list = sent_string.split('\\n')\n",
    "\n",
    "intersection_list = []\n",
    "\n",
    "for i in range(len(sample_sentence_list)):\n",
    "    current_sent = sample_sentence_list[i]\n",
    "    current_sent = current_sent.translate(str.maketrans('', '', string.punctuation))\n",
    "    sent_set = current_sent.split(' ')\n",
    "    intersection = [element for element in sent_set if element in json_hate_word_list]\n",
    "    intersection_list.append(intersection)\n",
    "\n",
    "print(intersection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'idiots', 'hateful_meaning': 'A mentally retarded person.', 'offensive_score': 17, 'variant_of': None, 'occurances': 0}\n"
     ]
    }
   ],
   "source": [
    "#Code to be completed when we are ranking based on toxicity to pick up the top 3 intersection words\n",
    "for element in json_file_data:\n",
    "        for inter_word in intersection:\n",
    "            if element['word'] == inter_word:\n",
    "                print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add space perturbation\n",
    "\n",
    "def add_space_perturbation(current_sent, intersection_words, position):\n",
    "    for word in intersection_words:\n",
    "        perturbation_word = word[:position] + ' ' + word[position:]\n",
    "        current_sent = current_sent.replace(word, perturbation_word)\n",
    "    return current_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add underscore perturbation\n",
    "\n",
    "def add_underscore_perturbation(current_sent, intersection_words, position):\n",
    "    for word in intersection_words:\n",
    "        perturbation_word = word[:position] + '_' + word[position:]\n",
    "        current_sent = current_sent.replace(word, perturbation_word)\n",
    "    return current_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add hash perturbation\n",
    "\n",
    "def add_hash_perturbation(current_sent, intersection_words, position):\n",
    "    for word in intersection_words:\n",
    "        perturbation_word = word[:position] + '#' + word[position:]\n",
    "        current_sent = current_sent.replace(word, perturbation_word)\n",
    "    return current_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add hash perturbation\n",
    "\n",
    "def add_hash_perturbation_combined(current_sent, intersection_words, position):\n",
    "    for word in intersection_words:\n",
    "        perturbation_word = word[:position] + '#' + word[position:]\n",
    "        current_sent = current_sent.replace(word, perturbation_word)\n",
    "        intersection_words = [w.replace(word, perturbation_word) for w in intersection_words]\n",
    "    return intersection_words, current_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over intersection_list and generate various perturbations\n",
    "\n",
    "space_perturbations_list = []\n",
    "underscore_perturbations_list = []\n",
    "hash_perturbations_list = []\n",
    "\n",
    "for i in range(len(sample_sentence_list)):\n",
    "    current_sent = sample_sentence_list[i]\n",
    "    current_sent = current_sent.translate(str.maketrans('', '', string.punctuation))\n",
    "    if intersection_list[i] != []:\n",
    "        space_perturbations_list.append(add_space_perturbation(current_sent, intersection_list[i], 1))\n",
    "        underscore_perturbations_list.append(add_underscore_perturbation(current_sent, intersection_list[i], 1))\n",
    "        hash_perturbations_list.append(add_hash_perturbation(current_sent, intersection_list[i], 1))\n",
    "#     else:\n",
    "#         space_perturbations_list.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ping_perspective(list_to_test):\n",
    "    toxicity_list = []\n",
    "    for values in list_to_test: \n",
    "        analyze_request = {\n",
    "          'comment': { 'text': values },\n",
    "          'requestedAttributes': {'TOXICITY': {}}\n",
    "        }\n",
    "\n",
    "        response = service.comments().analyze(body=analyze_request).execute()\n",
    "        toxicity_score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "        sent_toxicity = {'sent': values, 'offensive_score': toxicity_score}\n",
    "        toxicity_list.append(sent_toxicity)\n",
    "        sleep(0.5)\n",
    "    return toxicity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'sent': 'Climate change is happening and it’s not changing in our favor. If you think differently you’re an idiot. ', 'offensive_score': 0.956538}, {'sent': 'They’re stupid, it’s getting warmer, we should enjoy it while it lasts ', 'offensive_score': 0.9025232}, {'sent': 'They are liberal idiots who are uneducated', 'offensive_score': 0.9612263}, {'sent': 'idiots. backward thinking people.nationalists. not accepting facts. susceptible to lies.', 'offensive_score': 0.9629933}, {'sent': 'They are stupid and ignorant with no class', 'offensive_score': 0.94774556}, {'sent': 'It’s stupid and wrong ', 'offensive_score': 0.8687036}, {'sent': 'If they voted for Hilary they are idiots', 'offensive_score': 0.9657983}, {'sent': 'Anyone who voted for Trump is a moron', 'offensive_score': 0.9543542}, {'sent': 'Screw you trump supporters', 'offensive_score': 0.86969364}, {'sent': 'You forgot to mention just how smart the jews are, next they will make a deadly virus to kill ALL people BUT the jews!!', 'offensive_score': 0.83785176}, {'sent': 'Queers are an abomination and need to be helped to go straight to Hell!', 'offensive_score': 0.83785176}, {'sent': \"Now that Trump is president, I'm going to shoot you and all the blacks I can find\", 'offensive_score': 0.9095692}, {'sent': 'We’re going to take over all the political institutions of California. California is going to be a Hispanic state and anyone who doesn’t like it should leave. If they [Anglos] don’t like Mexicans, they ought to go back to Europe.', 'offensive_score': 0.5328147}, {'sent': 'There is plenty to blame whiteness for. There is no crime that whiteness has not committed against people of color. There is no crime that we have not committed even against ourselves … We must blame whiteness for the continuing patterns today that deny the rights of those outside of whiteness and which damage and pervert the humanity of those of us within it.', 'offensive_score': 0.56058156}, {'sent': 'Check your white privileges you cis white male.', 'offensive_score': 0.5342384}]]\n",
      "\n",
      "**************\n",
      "\n",
      "[[{'sent': 'Climate change is happening and it’s not changing in our favor If you think differently you’re an i diot ', 'offensive_score': 0.43813437}, {'sent': 'They’re s tupid it’s getting warmer we should enjoy it while it lasts ', 'offensive_score': 0.7388681}, {'sent': 'They are liberal i diots who are u neducated', 'offensive_score': 0.81733054}, {'sent': 'i diots b ackward thinking peoplenationalists not accepting facts s usceptible to l ies', 'offensive_score': 0.83785176}, {'sent': 'They are s tupid and i gnorant with no class', 'offensive_score': 0.76113284}, {'sent': 'It’s s tupid and w rong ', 'offensive_score': 0.6352936}, {'sent': 'If they voted for Hilary they are i diots', 'offensive_score': 0.8587314}, {'sent': 'Anyone who voted for Trump is a m oron', 'offensive_score': 0.55877036}, {'sent': 'You forgot to mention just how smart the j ews are next they will make a d eadly v irus to k ill ALL people BUT the j ews', 'offensive_score': 0.49795884}, {'sent': 'Queers are an a bomination and need to be helped to go straight to Hell', 'offensive_score': 0.83497435}, {'sent': 'Now that Trump is president Im going to shoot you and all the b lacks I can find', 'offensive_score': 0.76678485}, {'sent': 'There is plenty to b lame whiteness for There is no c rime that whiteness has not committed against people of color There is no c rime that we have not committed even against ourselves … We must b lame whiteness for the continuing patterns today that d eny the rights of those outside of whiteness and which d amage and p ervert the humanity of those of us within it', 'offensive_score': 0.52636063}]]\n",
      "\n",
      "**************\n",
      "\n",
      "[[{'sent': 'Climate change is happening and it’s not changing in our favor If you think differently you’re an i_diot ', 'offensive_score': 0.66553557}, {'sent': 'They’re s_tupid it’s getting warmer we should enjoy it while it lasts ', 'offensive_score': 0.46876037}, {'sent': 'They are liberal i_diots who are u_neducated', 'offensive_score': 0.53479165}, {'sent': 'i_diots b_ackward thinking peoplenationalists not accepting facts s_usceptible to l_ies', 'offensive_score': 0.29029423}, {'sent': 'They are s_tupid and i_gnorant with no class', 'offensive_score': 0.43460655}, {'sent': 'It’s s_tupid and w_rong ', 'offensive_score': 0.19901448}, {'sent': 'If they voted for Hilary they are i_diots', 'offensive_score': 0.61068445}, {'sent': 'Anyone who voted for Trump is a m_oron', 'offensive_score': 0.76644164}, {'sent': 'You forgot to mention just how smart the j_ews are next they will make a d_eadly v_irus to k_ill ALL people BUT the j_ews', 'offensive_score': 0.24391998}, {'sent': 'Queers are an a_bomination and need to be helped to go straight to Hell', 'offensive_score': 0.837847}, {'sent': 'Now that Trump is president Im going to shoot you and all the b_lacks I can find', 'offensive_score': 0.7742297}, {'sent': 'There is plenty to b_lame whiteness for There is no c_rime that whiteness has not committed against people of color There is no c_rime that we have not committed even against ourselves … We must b_lame whiteness for the continuing patterns today that d_eny the rights of those outside of whiteness and which d_amage and p_ervert the humanity of those of us within it', 'offensive_score': 0.36629152}]]\n",
      "\n",
      "**************\n",
      "\n",
      "[[{'sent': 'Climate change is happening and it’s not changing in our favor If you think differently you’re an i#diot ', 'offensive_score': 0.44246736}, {'sent': 'They’re s#tupid it’s getting warmer we should enjoy it while it lasts ', 'offensive_score': 0.7664774}, {'sent': 'They are liberal i#diots who are u#neducated', 'offensive_score': 0.86699563}, {'sent': 'i#diots b#ackward thinking peoplenationalists not accepting facts s#usceptible to l#ies', 'offensive_score': 0.8735591}, {'sent': 'They are s#tupid and i#gnorant with no class', 'offensive_score': 0.76694053}, {'sent': 'It’s s#tupid and w#rong ', 'offensive_score': 0.87016135}, {'sent': 'If they voted for Hilary they are i#diots', 'offensive_score': 0.83785176}, {'sent': 'Anyone who voted for Trump is a m#oron', 'offensive_score': 0.60850906}, {'sent': 'You forgot to mention just how smart the j#ews are next they will make a d#eadly v#irus to k#ill ALL people BUT the j#ews', 'offensive_score': 0.5704197}, {'sent': 'Queers are an a#bomination and need to be helped to go straight to Hell', 'offensive_score': 0.8040049}, {'sent': 'Now that Trump is president Im going to shoot you and all the b#lacks I can find', 'offensive_score': 0.83785176}, {'sent': 'There is plenty to b#lame whiteness for There is no c#rime that whiteness has not committed against people of color There is no c#rime that we have not committed even against ourselves … We must b#lame whiteness for the continuing patterns today that d#eny the rights of those outside of whiteness and which d#amage and p#ervert the humanity of those of us within it', 'offensive_score': 0.6117797}]]\n"
     ]
    }
   ],
   "source": [
    "#Test Toxicity score of each new perturbation kind\n",
    "\n",
    "from googleapiclient import discovery\n",
    "from time import sleep\n",
    "\n",
    "toxicity_list_original = []\n",
    "toxicity_list_spaces = []\n",
    "toxicity_list_underscore = []\n",
    "toxicity_list_hash = []\n",
    "\n",
    "API_KEY='AIzaSyBwhKOmTT0kNY5rQ-ME_m-ckJFGREPc9aw'\n",
    "# Generates API client object dynamically based on service name and version.\n",
    "service = discovery.build('commentanalyzer', 'v1alpha1', developerKey=API_KEY)\n",
    "toxicity_list_original.append(ping_perspective(sample_sentence_list))\n",
    "toxicity_list_spaces.append(ping_perspective(space_perturbations_list))\n",
    "toxicity_list_underscore.append(ping_perspective(underscore_perturbations_list))\n",
    "toxicity_list_hash.append(ping_perspective(hash_perturbations_list))\n",
    "\n",
    "print(toxicity_list_original)\n",
    "print('\\n**************\\n')\n",
    "print(toxicity_list_spaces)\n",
    "print('\\n**************\\n')\n",
    "print(toxicity_list_underscore)\n",
    "print('\\n**************\\n')\n",
    "print(toxicity_list_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i#diot']\n",
      "**\n",
      "['s#tupid']\n",
      "**\n",
      "['i#diots', 'u#neducated']\n",
      "**\n",
      "['i#diots', 'b#ackward', 's#usceptible', 'l#ies']\n",
      "**\n",
      "['s#tupid', 'i#gnorant']\n",
      "**\n",
      "['s#tupid', 'w#rong']\n",
      "**\n",
      "['i#diots']\n",
      "**\n",
      "['m#oron']\n",
      "**\n",
      "['j#ews', 'd#eadly', 'v#irus', 'k#ill', 'j#ews']\n",
      "**\n",
      "['a#bomination']\n",
      "**\n",
      "['b#lacks']\n",
      "**\n",
      "['b#lame', 'c#rime', 'c#rime', 'b#lame', 'd#eny', 'd#amage', 'p#ervert']\n",
      "**\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Loop over intersection_list and generate various combination perturbations\n",
    "\n",
    "combined_perturbations_list = []\n",
    "hash_modified_intersection_list = []\n",
    "\n",
    "for i in range(len(sample_sentence_list)):\n",
    "    current_sent = sample_sentence_list[i]\n",
    "    current_sent = current_sent.translate(str.maketrans('', '', string.punctuation))\n",
    "    if intersection_list[i] != []:\n",
    "        hash_modified_intersection_list, hash_modified_sent = add_hash_perturbation_combined(current_sent, intersection_list[i], 1)\n",
    "        underscore_modified_sent = add_underscore_perturbation(hash_modified_sent, hash_modified_intersection_list[i], 2)\n",
    "        space_modified_sent = add_underscore_perturbation(underscore_modified_sent, intersection_list[i], 3)\n",
    "        combined_perturbations_list.append(space_modified_sent)\n",
    "        \n",
    "print(combined_perturbations_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
